{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2b53b-9dd2-4ff9-b0c4-4acdc04955cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import shape, Point\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b25d5-2c68-446c-a157-aafc8ba6807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib parameters for better visualization\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b01f5b-1ef1-4f06-970a-c7d7b56cda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors for consistent city representation\n",
    "PARIS_COLOR = 'blue'\n",
    "LONDON_COLOR = 'green'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2d016-74eb-4b18-ae82-475c65836bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# GLOBAL PARAMETERS FOR london_rentals.xls\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393f692-5871-4230-8adb-94985cc6c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "LONDON_START_YEAR = 2012\n",
    "LONDON_END_YEAR = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cb9fd-3177-4fec-a4f0-18b75a8a4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# UTILITY FUNCTIONS\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73367d26-f064-446d-8e5b-3f34a3a97cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_from_coords(row, lon_idx, lat_idx):\n",
    "    \"\"\"Create a shapely Point from longitude and latitude columns\"\"\"\n",
    "    try:\n",
    "        lon, lat = row.iloc[lon_idx], row.iloc[lat_idx]\n",
    "        return Point(lon, lat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating point: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_paris_coords(coord_str):\n",
    "    \"\"\"Parse coordinate string from Paris data format\"\"\"\n",
    "    try:\n",
    "        lat_str, lon_str = coord_str.split(',')\n",
    "        lat = float(lat_str.strip())\n",
    "        lon = float(lon_str.strip())\n",
    "        return Point(lon, lat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing coordinates: {e}\")\n",
    "        return None\n",
    "        \n",
    "def convert_geojson_to_shape(geo_str):\n",
    "    \"\"\"Convert GeoJSON string to shapely geometry object\"\"\"\n",
    "    try:\n",
    "        geo_dict = json.loads(geo_str)\n",
    "        return shape(geo_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting geometry: {e}\")\n",
    "        return None\n",
    "\n",
    "def fit_polynomial_models(X, Y, max_degree=5):\n",
    "    \"\"\"Fit polynomial models of different degrees and perform cross-validation\"\"\"\n",
    "    degrees = range(1, max_degree + 1)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_results_list = []\n",
    "\n",
    "    for deg in degrees:\n",
    "        poly = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        lr = LinearRegression()\n",
    "        cv_results = cross_validate(lr, X_poly, Y, cv=kf, \n",
    "                                   scoring='neg_mean_squared_error', \n",
    "                                   return_train_score=True)\n",
    "        train_mse = -np.mean(cv_results['train_score'])\n",
    "        test_mse = -np.mean(cv_results['test_score'])\n",
    "        cv_results_list.append({\n",
    "            'degree': deg, \n",
    "            'train_mse': train_mse, \n",
    "            'test_mse': test_mse\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(cv_results_list)\n",
    "### PLOTS\n",
    "# For the scatter plot of Airbnb densities\n",
    "def plot_airbnb_density_scatter_comparison(paris_data, london_data):\n",
    "    \"\"\"Create side-by-side scatter plots comparing Airbnb density vs price changes\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Paris scatter plot\n",
    "    axes[0].scatter(paris_data['price_increase'], paris_data['airbnb_density'], \n",
    "                alpha=0.7, color=PARIS_COLOR)\n",
    "    axes[0].set_xlabel('Rental Price Increase (2024 - 2019) [€/m²]')\n",
    "    axes[0].set_ylabel('Airbnb Density (listings/km²)')\n",
    "    axes[0].set_title('Paris: Airbnb Density vs. Rental Price Increase')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # London scatter plot\n",
    "    axes[1].scatter(london_data['price_change'], london_data['airbnb_density'], \n",
    "                alpha=0.7, color=LONDON_COLOR)\n",
    "    axes[1].set_xlabel(f'Rental Price Change ({LONDON_END_YEAR}–{LONDON_START_YEAR})')\n",
    "    axes[1].set_ylabel('Airbnb Density (listings/km²)')\n",
    "    axes[1].set_title('London: Airbnb Density vs. Rental Price Change')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "secret_observation = \"In London, Airbnb densities are even more strongly correlated with actual rental prices than with price increases !\"\n",
    "\n",
    "# For the bias-variance trade-off plots\n",
    "def plot_bias_variance_tradeoff_comparison(paris_cv_results, london_cv_results):\n",
    "    \"\"\"Plot bias-variance tradeoff curves for both cities side by side\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Paris curves\n",
    "    axes[0].plot(paris_cv_results['degree'], paris_cv_results['train_mse'], \n",
    "             marker='o', color=PARIS_COLOR, linestyle='-', label='Training MSE')\n",
    "    axes[0].plot(paris_cv_results['degree'], paris_cv_results['test_mse'], \n",
    "             marker='o', color=PARIS_COLOR, linestyle='--', label='Validation MSE')\n",
    "    axes[0].set_xlabel('Polynomial Degree')\n",
    "    axes[0].set_ylabel('Mean Squared Error')\n",
    "    axes[0].set_title('Paris: Bias-Variance Trade-Off')\n",
    "    axes[0].set_yscale('log')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # London curves\n",
    "    axes[1].plot(london_cv_results['degree'], london_cv_results['train_mse'], \n",
    "             marker='s', color=LONDON_COLOR, linestyle='-', label='Training MSE')\n",
    "    axes[1].plot(london_cv_results['degree'], london_cv_results['test_mse'], \n",
    "             marker='s', color=LONDON_COLOR, linestyle='--', label='Validation MSE')\n",
    "    axes[1].set_xlabel('Polynomial Degree')\n",
    "    axes[1].set_ylabel('Mean Squared Error')\n",
    "    axes[1].set_title('London: Bias-Variance Trade-Off')\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "# For polynomial regression plots\n",
    "def plot_polynomial_regression_comparison(paris_X, paris_Y, paris_poly, paris_model, paris_r, paris_deg,\n",
    "                                         london_X, london_Y, london_poly, london_model, london_r, london_deg):\n",
    "    \"\"\"Plot polynomial regression curves for both cities side by side\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Paris regression\n",
    "    paris_X_range = np.linspace(paris_X.min(), paris_X.max(), 100).reshape(-1, 1)\n",
    "    paris_X_range_poly = paris_poly.transform(paris_X_range)\n",
    "    paris_Y_pred = paris_model.predict(paris_X_range_poly)\n",
    "    \n",
    "    axes[0].scatter(paris_X, paris_Y, alpha=0.7, color=PARIS_COLOR, label='Neighborhoods')\n",
    "    axes[0].plot(paris_X_range, paris_Y_pred, color=PARIS_COLOR, linestyle='--', \n",
    "             label=f'Polynomial Regression (deg {paris_deg}, R = {paris_r:.2f})')\n",
    "    axes[0].set_xlabel('Rental Price Increase (2024 - 2019) [€/m²]')\n",
    "    axes[0].set_ylabel('Airbnb Density (listings/km²)')\n",
    "    axes[0].set_title('Paris: Airbnb Density vs. Rental Price Increase')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # London regression\n",
    "    london_X_range = np.linspace(london_X.min(), london_X.max(), 100).reshape(-1, 1)\n",
    "    london_X_range_poly = london_poly.transform(london_X_range)\n",
    "    london_Y_pred = london_model.predict(london_X_range_poly)\n",
    "    \n",
    "    axes[1].scatter(london_X, london_Y, alpha=0.7, color=LONDON_COLOR, label='Neighborhoods')\n",
    "    axes[1].plot(london_X_range, london_Y_pred, color=LONDON_COLOR, linestyle='--', \n",
    "             label=f'Polynomial Regression (deg {london_deg}, R = {london_r:.2f})')\n",
    "    axes[1].set_xlabel(f'Rental Price Change ({LONDON_END_YEAR}–{LONDON_START_YEAR})')\n",
    "    axes[1].set_ylabel('Airbnb Density (listings/km²)')\n",
    "    axes[1].set_title('London: Airbnb Density vs. Rental Price Change')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "# For density distribution as bar chart\n",
    "def plot_density_distribution_comparison(paris_data, london_data):\n",
    "    \"\"\"Create side-by-side histograms for Airbnb density distributions\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Paris density distribution\n",
    "    sns.histplot(\n",
    "        paris_data['airbnb_density'], \n",
    "        kde=False, \n",
    "        ax=axes[0], \n",
    "        color=PARIS_COLOR,\n",
    "        stat='density',\n",
    "        bins=15,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    axes[0].set_title('Paris: Airbnb Density Distribution', fontsize=14)\n",
    "    axes[0].set_xlabel('Airbnb Density (listings/km²)', fontsize=12)\n",
    "    axes[0].set_ylabel('Density', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # London density distribution\n",
    "    sns.histplot(\n",
    "        london_data['airbnb_density'], \n",
    "        kde=False, \n",
    "        ax=axes[1], \n",
    "        color=LONDON_COLOR,\n",
    "        stat='density',\n",
    "        bins=15,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    axes[1].set_title('London: Airbnb Density Distribution', fontsize=14)\n",
    "    axes[1].set_xlabel('Airbnb Density (listings/km²)', fontsize=12)\n",
    "    axes[1].set_ylabel('Density', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "def fit_best_model(X, Y, cv_results_df):\n",
    "    \"\"\"Fit the best polynomial model based on cross-validation results\"\"\"\n",
    "    best_row = cv_results_df.loc[cv_results_df['test_mse'].idxmin()]\n",
    "    best_deg = int(best_row['degree'])\n",
    "    \n",
    "    poly_best = PolynomialFeatures(degree=best_deg, include_bias=False)\n",
    "    X_poly_best = poly_best.fit_transform(X)\n",
    "    lr_best = LinearRegression()\n",
    "    lr_best.fit(X_poly_best, Y)\n",
    "    r2_best = lr_best.score(X_poly_best, Y)\n",
    "    r_best = np.sqrt(r2_best) if r2_best >= 0 else 0\n",
    "    \n",
    "    return best_deg, poly_best, lr_best, r_best\n",
    "\n",
    "\n",
    "def plot_boxplot_comparison(paris_df, london_df):\n",
    "    \"\"\"Create side-by-side boxplots for both cities\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Paris boxplot\n",
    "    sns.boxplot(x='price_increase_bin', y='airbnb_density', data=paris_df, ax=axes[0], color=PARIS_COLOR)\n",
    "    axes[0].set_title(\"Paris: Distribution of Airbnb Density by Price Increase Bins\")\n",
    "    axes[0].set_xlabel(\"Rental Price Increase (2024 - 2019) [€/m²] (Binned)\")\n",
    "    axes[0].set_ylabel(\"Airbnb Density (listings per km²)\")\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # London boxplot\n",
    "    sns.boxplot(x='price_bin', y='airbnb_density', data=london_df, ax=axes[1], color=LONDON_COLOR)\n",
    "    axes[1].set_title(f\"London: Distribution of Airbnb Density by Price Change Bins\")\n",
    "    axes[1].set_xlabel(f\"Price Change ({LONDON_END_YEAR}–{LONDON_START_YEAR}) Quintile\")\n",
    "    axes[1].set_ylabel(\"Airbnb Density (listings per km²)\")\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "def plot_quadratic_fit_comparison(paris_df, london_df, paris_best_deg, london_best_deg):\n",
    "    \"\"\"Plot polynomial fits on binned data for both cities with R² values using best degree\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Paris polynomial fit\n",
    "    paris_bin_stats = paris_df.groupby('price_increase_bin', observed=False).agg({\n",
    "        'price_increase': 'mean', \n",
    "        'airbnb_density': 'median'\n",
    "    }).reset_index()\n",
    "    \n",
    "    paris_X = paris_bin_stats['price_increase'].values.reshape(-1, 1)\n",
    "    paris_y = paris_bin_stats['airbnb_density'].values\n",
    "    \n",
    "    paris_poly = PolynomialFeatures(degree=paris_best_deg, include_bias=False)\n",
    "    paris_X_poly = paris_poly.fit_transform(paris_X)\n",
    "    paris_model = LinearRegression()\n",
    "    paris_model.fit(paris_X_poly, paris_y)\n",
    "    \n",
    "    # Calculate R² for Paris model\n",
    "    paris_y_pred = paris_model.predict(paris_X_poly)\n",
    "    paris_r2 = r2_score(paris_y, paris_y_pred)\n",
    "    \n",
    "    paris_X_curve = np.linspace(paris_df['price_increase'].min(), paris_df['price_increase'].max(), 100).reshape(-1, 1)\n",
    "    paris_y_curve = paris_model.predict(paris_poly.transform(paris_X_curve))\n",
    "    \n",
    "    axes[0].scatter(paris_X, paris_y, color=PARIS_COLOR, s=80, label='Bin Medians')\n",
    "    axes[0].plot(paris_X_curve, paris_y_curve, color=PARIS_COLOR, linestyle='--', label=f'Degree {paris_best_deg} Fit')\n",
    "    \n",
    "    # Add bin edge vertical lines for Paris\n",
    "    paris_bin_edges = pd.unique(paris_df['price_increase_bin'].cat.categories.right.values[:-1])\n",
    "    for edge in paris_bin_edges:\n",
    "        axes[0].axvline(x=edge, color='gray', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    axes[0].set_title(f\"Paris: Degree {paris_best_deg} Regression on Binned Data (R² = {paris_r2:.3f})\")\n",
    "    axes[0].set_xlabel(\"Mean Price Increase (2024 - 2019) (€/m²)\")\n",
    "    axes[0].set_ylabel(\"Median Airbnb Density (listings/km²)\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # London polynomial fit\n",
    "    london_bin_stats = london_df.groupby('price_bin', observed=False).agg({\n",
    "        'price_change': 'mean', \n",
    "        'airbnb_density': 'median'\n",
    "    }).reset_index()\n",
    "    \n",
    "    london_X = london_bin_stats['price_change'].values.reshape(-1, 1)\n",
    "    london_y = london_bin_stats['airbnb_density'].values\n",
    "    \n",
    "    london_poly = PolynomialFeatures(degree=london_best_deg, include_bias=False)\n",
    "    london_X_poly = london_poly.fit_transform(london_X)\n",
    "    london_model = LinearRegression()\n",
    "    london_model.fit(london_X_poly, london_y)\n",
    "    \n",
    "    # Calculate R² for London model\n",
    "    london_y_pred = london_model.predict(london_X_poly)\n",
    "    london_r2 = r2_score(london_y, london_y_pred)\n",
    "    \n",
    "    london_X_curve = np.linspace(london_df['price_change'].min(), london_df['price_change'].max(), 100).reshape(-1, 1)\n",
    "    london_y_curve = london_model.predict(london_poly.transform(london_X_curve))\n",
    "    \n",
    "    axes[1].scatter(london_X, london_y, color=LONDON_COLOR, s=80, label='Bin Medians')\n",
    "    axes[1].plot(london_X_curve, london_y_curve, color=LONDON_COLOR, linestyle='--', label=f'Degree {london_best_deg} Fit')\n",
    "    \n",
    "    # Add bin edge vertical lines for London\n",
    "    london_bin_edges = pd.unique(london_df['price_bin'].cat.categories.right.values[:-1])\n",
    "    for edge in london_bin_edges:\n",
    "        axes[1].axvline(x=edge, color='gray', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    axes[1].set_title(f\"London: Degree {london_best_deg} Regression on Binned Data (R² = {london_r2:.3f})\")\n",
    "    axes[1].set_xlabel(f\"Mean Price Change ({LONDON_END_YEAR}–{LONDON_START_YEAR})\")\n",
    "    axes[1].set_ylabel(\"Median Airbnb Density (listings/km²)\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "# For correlation bar chart\n",
    "def plot_correlation_bar_chart(paris_corr, london_corr, paris_pvalue, london_pvalue):\n",
    "    \"\"\"Plot a bar chart comparing Pearson correlations for Paris and London with p-value annotations.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(\n",
    "        ['Paris', 'London'],\n",
    "        [paris_corr, london_corr],\n",
    "        color=[PARIS_COLOR, LONDON_COLOR],\n",
    "        edgecolor='black',\n",
    "        alpha=0.85\n",
    "    )\n",
    "    plt.axhline(y=0, color='red', linestyle='--', alpha=0.4, linewidth=1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.title('Correlation between Rental Price Changes and Airbnb Density', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Pearson Correlation Coefficient', fontsize=13)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle=':')\n",
    "    \n",
    "    # Annotate correlation values on bars\n",
    "    for idx, (corr, pval) in enumerate(zip([paris_corr, london_corr], [paris_pvalue, london_pvalue])):\n",
    "        plt.text(\n",
    "            idx, corr + (0.07 if corr > 0 else -0.13),\n",
    "            f\"r={corr:.2f}\\np={pval:.4f}\",\n",
    "            ha='center', va='bottom' if corr > 0 else 'top',\n",
    "            fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"gray\", alpha=0.7)\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_london_price_comparisons(london_data, london_best_deg):\n",
    "    \"\"\"\n",
    "    Plot side-by-side comparison of:\n",
    "    1. Airbnb density vs price change (polynomial regression)\n",
    "    2. Airbnb density vs latest rental price (linear regression)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    london_data : GeoDataFrame\n",
    "        London data containing 'airbnb_density', 'price_change', and latest price columns\n",
    "    london_best_deg : int\n",
    "        Best polynomial degree from cross-validation for London\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # LEFT PLOT: Airbnb density vs price change (polynomial regression)\n",
    "    london_X1 = london_data['price_change'].values.reshape(-1, 1)\n",
    "    london_Y = london_data['airbnb_density'].values\n",
    "    \n",
    "    # Polynomial regression for price change\n",
    "    london_poly = PolynomialFeatures(degree=london_best_deg, include_bias=False)\n",
    "    london_X1_poly = london_poly.fit_transform(london_X1)\n",
    "    london_model1 = LinearRegression()\n",
    "    london_model1.fit(london_X1_poly, london_Y)\n",
    "    \n",
    "    # Calculate R² and R for polynomial model\n",
    "    london_y_pred1 = london_model1.predict(london_X1_poly)\n",
    "    london_r2_1 = r2_score(london_Y, london_y_pred1)\n",
    "    london_r1 = np.sqrt(london_r2_1) if london_r2_1 >= 0 else 0\n",
    "    \n",
    "    # Plot scatter and regression line\n",
    "    axes[0].scatter(london_X1, london_Y, alpha=0.7, color=LONDON_COLOR)\n",
    "    \n",
    "    # Create smooth curve for polynomial fit\n",
    "    x_range = np.linspace(london_X1.min(), london_X1.max(), 100).reshape(-1, 1)\n",
    "    y_pred = london_model1.predict(london_poly.transform(x_range))\n",
    "    axes[0].plot(x_range, y_pred, color=LONDON_COLOR, linestyle='--', \n",
    "             label=f'Polynomial Regression (deg {london_best_deg}, R = {london_r1:.2f})')\n",
    "    \n",
    "    # Set labels and title\n",
    "    axes[0].set_xlabel(f'Rental Price Change ({LONDON_END_YEAR}–{LONDON_START_YEAR})')\n",
    "    axes[0].set_ylabel('Airbnb Density (listings/km²)')\n",
    "    axes[0].set_title('London: Airbnb Density vs. Price Change')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # RIGHT PLOT: Airbnb density vs latest rental price (linear regression)\n",
    "    london_X2 = london_data[f'avg_price_{LONDON_END_YEAR}'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Linear regression for latest price\n",
    "    london_model2 = LinearRegression()\n",
    "    london_model2.fit(london_X2, london_Y)\n",
    "    \n",
    "    # Calculate R² and R for linear model\n",
    "    london_r2_2 = r2_score(london_Y, london_model2.predict(london_X2))\n",
    "    london_r2 = np.sqrt(london_r2_2) if london_r2_2 >= 0 else 0\n",
    "    \n",
    "    # Plot scatter and regression line\n",
    "    axes[1].scatter(london_X2, london_Y, alpha=0.7, color=LONDON_COLOR)\n",
    "    \n",
    "    x_range = np.linspace(london_X2.min(), london_X2.max(), 100).reshape(-1, 1)\n",
    "    y_pred = london_model2.predict(x_range)\n",
    "    axes[1].plot(x_range, y_pred, color=LONDON_COLOR, linestyle='--', \n",
    "             label=f'Linear Regression (R = {london_r2:.2f})')\n",
    "    \n",
    "    # Set labels and title\n",
    "    axes[1].set_xlabel(f'Rental Price ({LONDON_END_YEAR})')\n",
    "    axes[1].set_ylabel('Airbnb Density (listings/km²)')\n",
    "    axes[1].set_title(f'London: Airbnb Density vs. Latest Price ({LONDON_END_YEAR})')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759deba-f9c4-414c-ba73-c7eafb75aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# DATA LOADING & PROCESSING\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b51812-ee0a-409a-9438-a578a3ecca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paris_data():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LOADING PARIS DATA\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # File paths\n",
    "    csv_rentals = \"../data/paris/paris_rentals.csv\"        # FETCH FROM : https://www.data.gouv.fr/fr/datasets/logement-encadrement-des-loyers/#:~:text=Ce%20jeu%20de%20donn%C3%A9es%20pr%C3%A9sente,des%20ann%C3%A9es%20pr%C3%A9c%C3%A9dentes%20est%20conserv%C3%A9\n",
    "    csv_airbnb = \"../data/paris/paris_airbnb.csv\"           # Airbnb listings : # FETCH FROM insideairbnb.com\n",
    "\n",
    "    df_rentals_initial = pd.read_csv(csv_rentals, \n",
    "                                     delimiter=';', \n",
    "                                     on_bad_lines='skip', \n",
    "                                     encoding='utf-8')\n",
    "    \n",
    "    # Use fine grid neighborhoods from rentals data (geojson is given)\n",
    "    df_neigh = df_rentals_initial.drop_duplicates(subset=\"Numéro du quartier\")\n",
    "    df_neigh = df_neigh[[\"Numéro du quartier\", \"geo_shape\"]]\n",
    "    print(f\"Number of unique Paris neighborhoods: {len(df_neigh)}\")\n",
    "    \n",
    "    # Rename and convert the GeoJSON geometry to Shapely objects\n",
    "    df_neigh.rename(columns={\"Numéro du quartier\": \"neigh_id\"}, inplace=True)\n",
    "    df_neigh[\"geometry\"] = df_neigh[\"geo_shape\"].apply(convert_geojson_to_shape)\n",
    "    gdf_neigh = gpd.GeoDataFrame(df_neigh, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Load Paris Airbnb data   :  # FETCH FROM insideairbnb.com\n",
    "    df_airbnb = pd.read_csv(csv_airbnb, \n",
    "                            delimiter=',', \n",
    "                            on_bad_lines='skip', \n",
    "                            encoding='utf-8')\n",
    "    \n",
    "    # Create point geometry from latitude and longitude\n",
    "    df_airbnb['geometry'] = df_airbnb.apply(lambda row: create_point_from_coords(row, 7, 6), axis=1)\n",
    "    df_airbnb = df_airbnb[df_airbnb['geometry'].notnull()]\n",
    "    gdf_airbnb = gpd.GeoDataFrame(df_airbnb, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Spatial join: assign Airbnb listings to neighborhoods\n",
    "    gdf_airbnb_joined = gpd.sjoin(gdf_airbnb, gdf_neigh, how='left', predicate='within')\n",
    "    airbnb_counts = gdf_airbnb_joined.groupby('neigh_id').size().reset_index(name='airbnb_count')\n",
    "    gdf_neigh = gdf_neigh.merge(airbnb_counts, on='neigh_id', how='left')\n",
    "    gdf_neigh['airbnb_count'] = gdf_neigh['airbnb_count'].fillna(0).astype(int)\n",
    "    \n",
    "    # Compute area in km² and calculate density\n",
    "    gdf_neigh['area_km2'] = gdf_neigh.to_crs(epsg=3857).area / 1e6\n",
    "    gdf_neigh['airbnb_density'] = gdf_neigh['airbnb_count'] / gdf_neigh['area_km2']\n",
    "    print(f\"Total number of Airbnb listings in Paris: {len(gdf_airbnb)}\")\n",
    "    \n",
    "    # Filter rental data by year\n",
    "    df_rentals_2024 = df_rentals_initial[df_rentals_initial.iloc[:, 0] == 2024].copy()\n",
    "    df_rentals_2019 = df_rentals_initial[df_rentals_initial.iloc[:, 0] == 2019].copy()\n",
    "    \n",
    "    # Parse coordinates and rental prices\n",
    "    df_rentals_2024['geometry'] = df_rentals_2024.iloc[:, 13].apply(parse_paris_coords)\n",
    "    df_rentals_2019['geometry'] = df_rentals_2019.iloc[:, 13].apply(parse_paris_coords)\n",
    "    \n",
    "    # Rental price is in column index 7\n",
    "    df_rentals_2024['rental_price'] = pd.to_numeric(df_rentals_2024.iloc[:, 7], errors='coerce')\n",
    "    df_rentals_2019['rental_price'] = pd.to_numeric(df_rentals_2019.iloc[:, 7], errors='coerce')\n",
    "    \n",
    "    # Filter valid entries\n",
    "    df_rentals_2024 = df_rentals_2024[df_rentals_2024['geometry'].notnull() & df_rentals_2024['rental_price'].notnull()]\n",
    "    df_rentals_2019 = df_rentals_2019[df_rentals_2019['geometry'].notnull() & df_rentals_2019['rental_price'].notnull()]\n",
    "    \n",
    "    # Create GeoDataFrames in preparation for spatial join\n",
    "    gdf_rentals_2024 = gpd.GeoDataFrame(df_rentals_2024, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    gdf_rentals_2019 = gpd.GeoDataFrame(df_rentals_2019, geometry='geometry', crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Spatial join rentals to neighborhoods\n",
    "    gdf_rentals_2024_joined = gpd.sjoin(gdf_rentals_2024, gdf_neigh, how='left', predicate='within')\n",
    "    gdf_rentals_2019_joined = gpd.sjoin(gdf_rentals_2019, gdf_neigh, how='left', predicate='within')\n",
    "    \n",
    "    # Calculate average prices for each neighborhood\n",
    "    avg_prices_2024 = gdf_rentals_2024_joined.groupby('neigh_id')['rental_price'].mean().reset_index(name='avg_rental_price_2024')\n",
    "    gdf_neigh = gdf_neigh.merge(avg_prices_2024, on='neigh_id', how='left')\n",
    "    gdf_neigh['avg_rental_price_2024'] = gdf_neigh['avg_rental_price_2024'].fillna(0)\n",
    "    \n",
    "    avg_prices_2019 = gdf_rentals_2019_joined.groupby('neigh_id')['rental_price'].mean().reset_index(name='avg_rental_price_2019')\n",
    "    gdf_neigh = gdf_neigh.merge(avg_prices_2019, on='neigh_id', how='left')\n",
    "    gdf_neigh['avg_rental_price_2019'] = gdf_neigh['avg_rental_price_2019'].fillna(0)\n",
    "    \n",
    "    # Compute rental price increase (2024 - 2019)\n",
    "    gdf_neigh['price_increase'] = gdf_neigh['avg_rental_price_2024'] - gdf_neigh['avg_rental_price_2019']\n",
    "    \n",
    "    return gdf_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d1aeb-2deb-4d79-b70c-fac6b1d3a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_london_data():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LOADING LONDON DATA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # File paths\n",
    "    excel_rentals = \"../data/london/london_rentals.xls\"        # rentals data : # FETCH FROM : https://data.london.gov.uk/dataset/average-private-rents-borough\n",
    "    csv_airbnb = \"../data/london/london_airbnb.csv\"           # Airbnb listings : # FETCH FROM insideairbnb.com\n",
    "    geojson_neigh = \"../data/london/london_neighbourhoods.geojson\"  # neighbourhood shapes\n",
    "    \n",
    "    # Load Airbnb listings\n",
    "    df_airbnb = pd.read_csv(csv_airbnb, encoding=\"utf-8\")\n",
    "    \n",
    "    # Build GeoDataFrame for Airbnb data\n",
    "    DF = df_airbnb.copy()\n",
    "    DF['geometry'] = DF.apply(lambda row: create_point_from_coords(row, 7, 6), axis=1)\n",
    "    DF = DF[DF['geometry'].notnull()]\n",
    "    gdf_airbnb = gpd.GeoDataFrame(DF, geometry='geometry', crs='EPSG:4326')\n",
    "    \n",
    "    # Load and process rental data\n",
    "    # positional column indices in the Excel\n",
    "    YEAR_COL, QUARTER_COL, NEIGH_COL, CATEGORY_COL, PRICE_COL = 0, 1, 3, 4, 6\n",
    "    NEIGH_NAME = 'neighbourhood'\n",
    "    \n",
    "    # read raw rentals sheet\n",
    "    raw = pd.read_excel(excel_rentals, sheet_name=\"Raw data\", header=None)\n",
    "    raw.rename(columns={NEIGH_COL: NEIGH_NAME}, inplace=True)\n",
    "    \n",
    "    # filter by years, Q1, all categories\n",
    "    df_filt = raw[(raw.iloc[:, YEAR_COL].isin([LONDON_START_YEAR, LONDON_END_YEAR])) &\n",
    "                   (raw.iloc[:, QUARTER_COL]=='Q1') &\n",
    "                   (raw.iloc[:, CATEGORY_COL]=='All categories')].copy()\n",
    "    \n",
    "    # parse price and drop NAs\n",
    "    df_filt[PRICE_COL] = pd.to_numeric(df_filt.iloc[:, PRICE_COL], errors='coerce')\n",
    "    df_filt.dropna(subset=[NEIGH_NAME, PRICE_COL], inplace=True)\n",
    "    \n",
    "    # average price per neighbourhood per year\n",
    "    avg_start = df_filt[df_filt.iloc[:, YEAR_COL]==LONDON_START_YEAR]\n",
    "    avg_start = avg_start.groupby(NEIGH_NAME)[PRICE_COL].mean().reset_index(name=f\"avg_price_{LONDON_START_YEAR}\")\n",
    "    avg_end = df_filt[df_filt.iloc[:, YEAR_COL]==LONDON_END_YEAR]\n",
    "    avg_end = avg_end.groupby(NEIGH_NAME)[PRICE_COL].mean().reset_index(name=f\"avg_price_{LONDON_END_YEAR}\")\n",
    "    \n",
    "    # merge average prices\n",
    "    df_rentals = pd.merge(avg_start, avg_end, on=NEIGH_NAME, how='outer').fillna(0)\n",
    "    \n",
    "    # compute price change always\n",
    "    df_rentals['price_change'] = df_rentals[f\"avg_price_{LONDON_END_YEAR}\"] - df_rentals[f\"avg_price_{LONDON_START_YEAR}\"]\n",
    "    \n",
    "    # Merge with neighbourhood geometries and compute Airbnb density\n",
    "    gdf_neigh = gpd.read_file(geojson_neigh)\n",
    "    gdf_neigh = gdf_neigh.merge(df_rentals, on=NEIGH_NAME, how='left').fillna(0)\n",
    "    joined = gpd.sjoin(gdf_airbnb, gdf_neigh, how='left', predicate='within')\n",
    "    counts = joined.groupby('neighbourhood_right').size().reset_index(name='airbnb_count')\n",
    "    counts.rename(columns={'neighbourhood_right':'neighbourhood'}, inplace=True)\n",
    "    gdf_neigh = gdf_neigh.merge(counts, on='neighbourhood', how='left').fillna({'airbnb_count':0})\n",
    "    gdf_neigh['area_km2'] = gdf_neigh.to_crs(epsg=3857).area / 1e6\n",
    "    gdf_neigh['airbnb_density'] = gdf_neigh['airbnb_count'] / gdf_neigh['area_km2']\n",
    "    \n",
    "    print(f\"Number of unique London neighborhoods: {len(gdf_neigh)}\")\n",
    "    print(f\"Total Airbnb listings in London: {len(gdf_airbnb)}\")\n",
    "    \n",
    "    return gdf_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7758a4-18e9-4afb-82a0-f9f920d19c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# COMPARATIVE ANALYSIS\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438eed1-f8ed-4723-900c-cd061366e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for both cities\n",
    "paris_data = load_paris_data()\n",
    "london_data = load_london_data()\n",
    "print(\"\\nOK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9c740-66fe-4db3-a53f-c60edb78a5d8",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## What are the Airbnb densities in Paris & London ?\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17271838-9827-4b21-9ecb-e5dcc52d6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Airbnb Density Maps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "paris_data.plot(column='airbnb_density', cmap='Blues', legend=True, ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Paris: Airbnb Density (listings/km²)')\n",
    "\n",
    "london_data.plot(column='airbnb_density', cmap='Greens', legend=True, ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title('London: Airbnb Density (listings/km²)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a29133-c7ea-4455-9a57-25975e79fc14",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## What are the long term rental price increase in Paris & London ?\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45d47f-40fb-4467-9c23-c2e13c110a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Rental Price Increase Maps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "paris_data.plot(column='price_increase', cmap='Blues', legend=True, ax=axes[0], edgecolor='black')\n",
    "axes[0].set_title('Paris: Rental Price Increase (2024 - 2019)')\n",
    "\n",
    "london_data.plot(column='price_change', cmap='Greens', legend=True, ax=axes[1], edgecolor='black')\n",
    "axes[1].set_title(f'London: Rental Price Change ({LONDON_END_YEAR}–{LONDON_START_YEAR})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65c104-1076-4d4f-b3c6-e798b9817360",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39585153-19f6-4702-9163-e8ccd0e5f266",
   "metadata": {},
   "source": [
    "## Market Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c8a72-ffa4-4296-9cc0-15c90a247e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Density Distribution Comparison\n",
    "fig, ax = plot_density_distribution_comparison(paris_data, london_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dd12e-bf19-44d3-a19a-710def1741ae",
   "metadata": {},
   "source": [
    "Right-skewed distributions suggest a few neighborhoods with very high Airbnb concentration, which might represent two distinct type of neighbourhoods : tourist vs residential)\n",
    "&nbsp;\n",
    "## The plot twist\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6c86f-a57f-4601-80f8-9a3585a01427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Scatter Plot: Airbnb Density vs Price Increase\n",
    "fig, axes = plot_airbnb_density_scatter_comparison(paris_data, london_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae151dbc-f0e9-4204-ab68-d8b5916ab370",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Let's do a simple polynomial regression\n",
    "### With cross validation to find the best degree of approximation\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a5715-6385-429c-9f9d-c84d44347918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Bias-Variance Trade-off Analysis\n",
    "paris_X = paris_data['price_increase'].values.reshape(-1, 1)\n",
    "paris_Y = paris_data['airbnb_density'].values\n",
    "paris_cv_results = fit_polynomial_models(paris_X, paris_Y)\n",
    "print(\"\\nParis Cross-validation results:\")\n",
    "print(paris_cv_results)\n",
    "\n",
    "london_X = london_data['price_change'].values.reshape(-1, 1)\n",
    "london_Y = london_data['airbnb_density'].values\n",
    "london_cv_results = fit_polynomial_models(london_X, london_Y)\n",
    "print(\"\\nLondon Cross-validation results:\")\n",
    "print(london_cv_results)\n",
    "\n",
    "fig, axes = plot_bias_variance_tradeoff_comparison(paris_cv_results, london_cv_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca64cc6-f4b5-446a-a822-c3db2c313733",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## What is the best polynomial degree to fit theses data points ?\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b32030-c8aa-4344-946b-5da43546aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best models for both Paris and London\n",
    "paris_best_deg, paris_poly, paris_model, paris_r = fit_best_model(paris_X, paris_Y, paris_cv_results)\n",
    "london_best_deg, london_poly, london_model, london_r = fit_best_model(london_X, london_Y, london_cv_results)\n",
    "\n",
    "print(f\"Best Polynomial Degree for Paris : {paris_best_deg}\")\n",
    "print(f\"Best Polynomial Degree for London : {london_best_deg}\")\n",
    "# 6. Plot polynomial regression comparison\n",
    "fig, axes = plot_polynomial_regression_comparison(\n",
    "    paris_X, paris_Y, paris_poly, paris_model, paris_r, paris_best_deg,\n",
    "    london_X, london_Y, london_poly, london_model, london_r, london_best_deg\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb011a5f-d284-496f-95bf-e86ff0c55759",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Can we get a better view of this tends ?\n",
    "### Using a box plot\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca43160-491f-4bdc-8905-d2c515b6c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Box Plots - with 5 bins\n",
    "paris_data['price_increase_bin'] = pd.qcut(paris_data['price_increase'], q=5, duplicates='drop')\n",
    "london_data['price_bin'] = pd.qcut(london_data['price_change'], q=5, duplicates='drop')\n",
    "\n",
    "plot_boxplot_comparison(paris_data, london_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606efe0-738e-4492-a56c-b01ef014e316",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## And an even better ?\n",
    "### By plotting the median of each bins of the box plots\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a75551-556c-4765-a248-68e79c26c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Quadratic Regression on Binned Data\n",
    "plot_quadratic_fit_comparison(paris_data, london_data, paris_best_deg, london_best_deg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5c4c3-6d74-4689-9a18-e9a49c837449",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## What are the correlation ?\n",
    "### By using pearson correlation\n",
    "The Pearson correlation coefficient encapsulates in a single value between –1 and 1 the strength and direction of a straight‑line relationship: +1 denotes perfect positive alignment, –1 perfect negative alignment, and 0 no linear connection.\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d377bb-c343-4d9c-9d87-cf39cfa616c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Pearson Correlation Comparison\n",
    "paris_corr, paris_pvalue = pearsonr(paris_data['price_increase'], paris_data['airbnb_density'])\n",
    "london_corr, london_pvalue = pearsonr(london_data['price_change'], london_data['airbnb_density'])\n",
    "\n",
    "# Create correlation bar chart\n",
    "plot_correlation_bar_chart(paris_corr, london_corr, paris_pvalue, london_pvalue)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Paris - Correlation between Price Increase and Airbnb Density: {paris_corr:.3f} (p-value: {paris_pvalue:.4f})\")\n",
    "print(f\"London - Correlation between Price Change and Airbnb Density: {london_corr:.3f} (p-value: {london_pvalue:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26166b53-41e8-4e32-b3e6-f87e8c0c987e",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "### Optional observation\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107276b-f11d-48a1-ba9e-8d69be5bb0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c38a4-8101-46bc-99cf-fc2bca8ba7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. London: Price Change vs Latest Price Comparison\n",
    "fig, axes = plot_london_price_comparisons(london_data, london_best_deg)\n",
    "plt.show()\n",
    "print(secret_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ad7d4-780b-4e49-883c-71617076e6d7",
   "metadata": {},
   "source": [
    "# Open-ended Challenge\n",
    "## a. Data to gather\n",
    "\n",
    "1. **Macroeconomic indicators**  \n",
    "   - GDP growth and unemployment rates (city/metro level)  \n",
    "   - Average wage or income growth  \n",
    "\n",
    "2. **Housing supply metrics**  \n",
    "   - Building permits, housing completions, vacancy rates  \n",
    "   - Land‑use policy changes (zoning amendments, rent‑control legislation)  \n",
    "\n",
    "3. **Demographic and migration flows**  \n",
    "   - Net migration (domestic + international)  \n",
    "   - Household formation rates  \n",
    "\n",
    "4. **Tourism and short‑term rentals**  \n",
    "   - Airbnb/VRBO listings over time and occupancy rates  \n",
    "   - Hotel capacity and visitor arrivals  \n",
    "\n",
    "5. **Financial conditions**  \n",
    "   - Mortgage rates and credit availability  \n",
    "   - Investor purchase volumes in residential real estate  \n",
    "\n",
    "---\n",
    "\n",
    "## b. Investigation and analytical structure\n",
    "\n",
    "1. **Define the incremental difference**  \n",
    "   - Compute Δ<sub>city</sub> = Rent<sub>t₁</sub> – Rent<sub>t₀</sub> for each city  \n",
    "   - Compare Δ<sub>City A</sub> – Δ<sub>City B</sub>  \n",
    "\n",
    "2. **Formulate hypotheses**  \n",
    "   - e.g. “City A’s higher rent growth is driven by tighter new supply”  \n",
    "\n",
    "3. **Data alignment & preprocessing**  \n",
    "   - Align time windows (e.g. annual Q1), geography (neighborhoods), and units (€/m² vs £/ft²)  \n",
    "   - Normalize variables (z‑scores) for comparability  \n",
    "\n",
    "4. **Descriptive & exploratory analysis**  \n",
    "   - Time‑series plots of candidate drivers vs. rent indices  \n",
    "   - Spatial maps showing rent increases and supply/demand indicators  \n",
    "\n",
    "5. **Multivariate regression**  \n",
    "   ```text\n",
    "   RentChange<sub>i,t</sub> = β₀ + β₁·SupplyGrowth<sub>i,t</sub> + β₂·IncomeGrowth<sub>i,t</sub> + β₃·AirbnbDensity<sub>i,t</sub> + … + ε<sub>i,t</sub>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f41ee-c947-4516-a8a5-3ee38a52b994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
